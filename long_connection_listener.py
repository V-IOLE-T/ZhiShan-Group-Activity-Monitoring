import os
import json
from dotenv import load_dotenv
import lark_oapi as lark
from lark_oapi.api.im.v1 import *
from datetime import datetime

# å¯¼å…¥ç°æœ‰æ¨¡å—
from auth import FeishuAuth
from calculator import MetricsCalculator
from storage import BitableStorage, MessageArchiveStorage
from collector import MessageCollector
from config import CACHE_USER_NAME_SIZE, CACHE_EVENT_SIZE, TOPIC_ACTIVE_DAYS, TOPIC_SILENT_DAYS
from pin_monitor import PinMonitor
from reply_card import DocCardProcessor
from utils import LRUCache
from storage import DocxStorage
from message_renderer import MessageToDocxConverter
from pin_scheduler import start_pin_scheduler, stop_pin_scheduler

load_dotenv()

# åˆå§‹åŒ–é…ç½®
APP_ID = os.getenv("APP_ID")
APP_SECRET = os.getenv("APP_SECRET")
CHAT_ID = os.getenv("CHAT_ID")
ARCHIVE_DOC_TOKEN = os.getenv("ARCHIVE_DOC_TOKEN")

# åˆå§‹åŒ–ç»„ä»¶
auth = FeishuAuth()
storage = BitableStorage(auth)
archive_storage = MessageArchiveStorage(auth)
collector = MessageCollector(auth)
calculator = MetricsCalculator([])
doc_processor = DocCardProcessor(auth)
docx_storage = DocxStorage(auth)
docx_converter = MessageToDocxConverter(docx_storage)


# æ ‡ç­¾æ˜ å°„é…ç½®
TAG_MAPPING = {
    "é—®ç­”": os.getenv("DOC_TOKEN_TAG_QA"),
    "æ‰“å¡": os.getenv("DOC_TOKEN_TAG_CHECKIN"),
    "é›…æ€": os.getenv("DOC_TOKEN_TAG_ENGLISH"), 
    "è‹±è¯­å­¦ä¹ ": os.getenv("DOC_TOKEN_TAG_ENGLISH"),
    "é›…æ€/è‹±è¯­å­¦ä¹ ": os.getenv("DOC_TOKEN_TAG_ENGLISH"),
    "AIå®ç”¨åˆ†äº«": os.getenv("DOC_TOKEN_TAG_AI"),
    "å†™ä½œè¿è¥": os.getenv("DOC_TOKEN_TAG_OPS"),
    "æ²Ÿé€šåœºæ™¯/æŠ€å·§": os.getenv("DOC_TOKEN_TAG_COMM"),
    "ä¸ªäººæ€è€ƒ": os.getenv("DOC_TOKEN_TAG_THINKING"),
    "æ”»ç•¥åˆ†äº«": os.getenv("DOC_TOKEN_TAG_GUIDE"),
}

def get_target_doc_token(message):
    """æ ¹æ®æ¶ˆæ¯å†…å®¹è·å–ç›®æ ‡æ–‡æ¡£ Token"""
    
    # 1. ç¡®å®šè¦æ£€æŸ¥çš„å†…å®¹
    # å¦‚æœæ˜¯å›å¤æ¶ˆæ¯ï¼Œéœ€è¦æ£€æŸ¥æ ¹æ¶ˆæ¯çš„å†…å®¹æ¥ç¡®å®šå½’æ¡£ä½ç½®
    check_content_str = message.content
    is_reply = bool(message.parent_id or message.root_id)
    
    if is_reply and message.root_id:
        # å°è¯•è·å–æ ¹æ¶ˆæ¯å†…å®¹
        # print(f"  > [è·¯ç”±] è¿™æ˜¯ä¸€æ¡å›å¤æ¶ˆæ¯ï¼Œæ­£åœ¨è·å–æ ¹æ¶ˆæ¯ {message.root_id} ä»¥ç¡®å®šæ ‡ç­¾...")
        try:
            root_msg = collector.get_message_detail(message.root_id)
            if root_msg:
                # root_msg['body']['content'] æ˜¯ JSON å­—ç¬¦ä¸²
                check_content_str = root_msg.get("body", {}).get("content", "")
        except Exception as e:
            print(f"  > [è·¯ç”±] è·å–æ ¹æ¶ˆæ¯å¤±è´¥: {e}")
            
    # 2. æå–çº¯æ–‡æœ¬ç”¨äºæ ‡ç­¾åŒ¹é…
    # ä½¿ç”¨ MetricsCalculator æå–æ–‡æœ¬ï¼Œæˆ–è€…ç®€å•è§£æ
    plain_text = ""
    try:
        # å°è¯•å¤ç”¨ç°æœ‰çš„æå–é€»è¾‘ï¼Œæˆ–è€…ç®€å•å®ç°
        if check_content_str:
            # ç®€å•è§£æï¼šå°è¯•æå– text å­—æ®µ
            try:
                content_obj = json.loads(check_content_str)
                # é€’å½’æå–æ‰€æœ‰ text å­—æ®µ
                def extract_text(obj):
                    texts = []
                    if isinstance(obj, dict):
                        for k, v in obj.items():
                            if k == 'text' and isinstance(v, str):
                                texts.append(v)
                            else:
                                texts.extend(extract_text(v))
                    elif isinstance(obj, list):
                        for item in obj:
                            texts.extend(extract_text(item))
                    return texts
                
                texts = extract_text(content_obj)
                plain_text = " ".join(texts)
            except:
                plain_text = check_content_str # Fallback
    except Exception as e:
        print(f"  > [è·¯ç”±] è§£ææ–‡æœ¬å¤±è´¥: {e}")
        plain_text = check_content_str

    # 3. æ£€æŸ¥æ ‡ç­¾
    # é»˜è®¤ä½¿ç”¨ ARCHIVE_DOC_TOKEN (å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä¸”æ²¡åŒ¹é…åˆ°æ ‡ç­¾ï¼Œåˆ™è¿”å› None)
    target_token = ARCHIVE_DOC_TOKEN or None
    matched_tag = "é»˜è®¤"
    
    if plain_text:
        # ä¼˜å…ˆåŒ¹é…é•¿æ ‡ç­¾
        sorted_tags = sorted(TAG_MAPPING.keys(), key=len, reverse=True)
        
        for tag in sorted_tags:
            token = TAG_MAPPING.get(tag)
            if not token: continue 
            
            # æ£€æŸ¥ #æ ‡ç­¾
            search_key = f"#{tag}"
            if search_key in plain_text:
                target_token = token
                matched_tag = tag
                break
                
    # print(f"  > [è·¯ç”±] æ ‡ç­¾: {matched_tag} -> æ–‡æ¡£: {target_token}")
    return target_token, matched_tag


# ç”¨æˆ·æ˜µç§°ç¼“å­˜ - ä½¿ç”¨LRUé˜²æ­¢å†…å­˜æ³„æ¼
user_name_cache = LRUCache(capacity=CACHE_USER_NAME_SIZE)

# äº‹ä»¶å»é‡ç¼“å­˜ - ä½¿ç”¨LRUé˜²æ­¢å†…å­˜æ³„æ¼
processed_events = LRUCache(capacity=CACHE_EVENT_SIZE)

# æ‰¹é‡æ›´æ–°é…ç½®
BATCH_UPDATE_THRESHOLD = 3  # æ¯ 3 æ¡æ¶ˆæ¯æ›´æ–°ä¸€æ¬¡
message_counter = 0
pending_updates = {}  # {user_id: {"user_name": str, "metrics": dict}}


def get_cached_nickname(user_id):
    """è·å–ç¼“å­˜çš„æ˜µç§°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä» API è·å–å¹¶æ›´æ–°ç¼“å­˜"""
    if not user_id:
        return user_id

    cached_name = user_name_cache.get(user_id)
    if cached_name:
        return cached_name

    print(f"æ­£åœ¨è·å–ç”¨æˆ· {user_id} çš„ç¾¤å¤‡æ³¨...")
    names = collector.get_user_names([user_id])
    if names:
        for uid, name in names.items():
            user_name_cache.set(uid, name)

    return user_name_cache.get(user_id, user_id)


def accumulate_metrics(user_id: str, user_name: str, metrics_delta: dict):
    """ç´¯ç§¯ç”¨æˆ·æŒ‡æ ‡åˆ°å¾…æ›´æ–°å­—å…¸"""
    global pending_updates
    
    if user_id not in pending_updates:
        pending_updates[user_id] = {
            "user_name": user_name,
            "metrics": {
                "message_count": 0,
                "char_count": 0,
                "reply_received": 0,
                "mention_received": 0,
                "topic_initiated": 0,
            }
        }
    
    # ç´¯åŠ æŒ‡æ ‡
    for key, value in metrics_delta.items():
        if key in pending_updates[user_id]["metrics"]:
            pending_updates[user_id]["metrics"][key] += value


def flush_pending_updates():
    """æ‰¹é‡æ›´æ–°æ‰€æœ‰å¾…å¤„ç†çš„ç”¨æˆ·ç»Ÿè®¡"""
    global pending_updates
    
    if not pending_updates:
        return
    
    print(f"ğŸ“Š æ‰¹é‡æ›´æ–° {len(pending_updates)} ä¸ªç”¨æˆ·çš„ç»Ÿè®¡æ•°æ®...")
    
    for user_id, data in pending_updates.items():
        try:
            storage.update_or_create_record(
                user_id, 
                data["user_name"], 
                data["metrics"]
            )
        except Exception as e:
            print(f"âŒ æ›´æ–° {data['user_name']} å¤±è´¥: {e}")
    
    pending_updates = {}
    print("âœ… æ‰¹é‡æ›´æ–°å®Œæˆ")


def do_p2_im_message_receive_v1(data: lark.im.v1.P2ImMessageReceiveV1) -> None:
    """å¤„ç†æ¥æ”¶æ¶ˆæ¯ v2.0 äº‹ä»¶"""
    from health_monitor import update_event_processed
    
    event = data.event
    message = event.message
    sender = event.sender

    # [V3-LOG] ç»å¯¹æœ€å‰ç½®æ—¥å¿—ï¼šåªè¦é£ä¹¦å‘äº†ï¼Œè¿™é‡Œå°±ä¸€å®šæœ‰è¾“å‡º
    now_str = datetime.now().strftime("%H:%M:%S")
    print(f"\n[V3-LOG] [{now_str}] æ”¶åˆ°åŸå§‹äº‹ä»¶é€šçŸ¥ =========================")
    print(f"  > äº‹ä»¶ID: {data.header.event_id}")
    print(f"  > æ¶ˆæ¯ç±»å‹: {message.message_type}")
    print(f"  > åŸå§‹å†…å®¹: {message.content[:200]}...")
    
    # æ›´æ–°å¥åº·ç›‘æ§çŠ¶æ€
    update_event_processed("message")

    # 0. äº‹ä»¶å»é‡
    event_id = data.header.event_id
    if event_id in processed_events:
        print(f"  > [æ‹¦æˆª] è¯¥äº‹ä»¶å·²å¤„ç†è¿‡ï¼Œè·³è¿‡ (å»é‡)")
        return
    processed_events.set(event_id, True)

    # è·å–å‘é€è€… OpenID
    sender_id = sender.sender_id.open_id
    if not sender_id:
        print(f"  > [æ‹¦æˆª] æ— æ³•è·å– sender_id")
        return

    # 1. è¯†åˆ«èŠå¤©ç±»å‹å¹¶æ‰§è¡Œè¿‡æ»¤
    chat_type = message.chat_type  # 'p2p' æˆ– 'group'
    is_p2p = (chat_type == "p2p")
    is_target_group = (chat_type == "group" and message.chat_id == CHAT_ID)

    print(f"  > [åˆ†æ] ä¼šè¯ç±»å‹: {chat_type}, æ˜¯å¦å•èŠ: {is_p2p}")

    # æƒ…å†µ Aï¼šå¦‚æœæ˜¯å•èŠï¼ˆP2Pï¼‰ï¼Œå¤„ç†æ–‡æ¡£é“¾æ¥æˆ–çº¯æ–‡æœ¬
    if is_p2p:
        print(f"  > [å•èŠ] æ”¶åˆ°å•èŠæ¶ˆæ¯ï¼Œå‡†å¤‡å¤„ç†...")
        try:
            # æå–æ¶ˆæ¯æ–‡æœ¬å†…å®¹
            message_text = ""
            if message.message_type == "text":
                try:
                    content_obj = json.loads(message.content)
                    message_text = content_obj.get("text", "")
                except:
                    message_text = message.content
            
            # æ£€æµ‹æ˜¯å¦åŒ…å«æ–‡æ¡£é“¾æ¥
            has_doc_link = doc_processor.extract_token(message_text)
            
            if has_doc_link:
                # å¤„ç†æ–‡æ¡£é“¾æ¥ï¼Œå‘é€å¡ç‰‡æ ·å¼å›¾ç‰‡ï¼ˆå¸¦ç»¿è‰²æ ‡é¢˜ï¼‰
                print(f"  > [å•èŠ] æ£€æµ‹åˆ°æ–‡æ¡£é“¾æ¥ï¼Œæ­£åœ¨ç”Ÿæˆå¡ç‰‡...")
                doc_processor.process_and_reply(message_text, message.chat_id)
            elif message_text.strip():
                # çº¯æ–‡æœ¬æ¶ˆæ¯ï¼Œç”Ÿæˆç®€æ´å›¾ç‰‡ï¼ˆæ— æ ‡é¢˜æ ï¼‰
                print(f"  > [å•èŠ] æ”¶åˆ°çº¯æ–‡æœ¬: {message_text[:50]}...")
                try:
                    from reply_card.image_generator import DocImageGenerator
                    generator = DocImageGenerator()
                    # çº¯æ–‡æœ¬ä½œä¸ºå†…å®¹ï¼Œæ ‡é¢˜ä¸ºç©º
                    image_data = generator.generate_doc_image("", message_text)
                    doc_processor._send_image_reply(message.chat_id, image_data)
                    print(f"  > [å•èŠ] âœ… çº¯æ–‡æœ¬å›¾ç‰‡å‘é€æˆåŠŸ")
                except Exception as e:
                    print(f"  > [å•èŠ] âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"  > [å•èŠ] æ¶ˆæ¯å†…å®¹ä¸ºç©ºæˆ–éæ–‡æœ¬ç±»å‹ï¼Œè·³è¿‡")
        except Exception as e:
            print(f"  > [å•èŠ] å¤„ç†å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        
        return  # å•èŠå¤„ç†å®Œæ¯•ï¼Œä¸å‚ä¸ç¾¤ç»„ç»Ÿè®¡é€»è¾‘

    # æƒ…å†µ Bï¼šå¦‚æœæ˜¯éç›®æ ‡ç¾¤ç»„ï¼Œè·³è¿‡
    if not is_target_group:
        return

    # æƒ…å†µ Cï¼šç›®æ ‡ç¾¤ç»„çš„æ¶ˆæ¯ï¼Œæ‰§è¡Œå½’æ¡£å’Œç»Ÿè®¡
    
    # [æ–°å¢] è‡ªåŠ¨å½’æ¡£ç¾¤æ¶ˆæ¯åˆ°æ–‡æ¡£
    # å°è¯•è·å–ç›®æ ‡æ–‡æ¡£ Tokenï¼Œå¦‚æœæ—¢æ²¡åŒ¹é…æ ‡ç­¾ä¹Ÿæ²¡é…ç½®é»˜è®¤æ–‡æ¡£ï¼Œåˆ™è¿”å› None
    target_doc_token, matched_tag = get_target_doc_token(message)

    if target_doc_token:
        try:
            print(f"  > [å½’æ¡£] æ­£åœ¨é‡‡é›†ç¾¤æ¶ˆæ¯åˆ°æ–‡æ¡£ {target_doc_token}...")
            
            # ... (ä¸­é—´ä»£ç ä¿æŒä¸å˜ï¼Œé€šè¿‡çœç•¥å·æˆ–ä¸éœ€è¦æ”¹åŠ¨) ... 
            # å®é™…ä¸Šç”±äº replace_file_content éœ€è¦è¿ç»­å—ï¼Œæˆ‘å¿…é¡»å®Œæ•´åŒ…å«

            # è·å–å‘é€è€…æ˜µç§°
            # sender.sender_id å¯èƒ½æœ‰å¤šç§æ ¼å¼ï¼Œéœ€è¦æ­£ç¡®æå–
            sender_id = None
            if sender and sender.sender_id:
                # å°è¯•è·å– user_id æˆ– open_id
                sender_id = getattr(sender.sender_id, 'user_id', None) or \
                           getattr(sender.sender_id, 'open_id', None) or \
                           getattr(sender.sender_id, 'union_id', None)
            
            if sender_id:
                sender_nickname = get_cached_nickname(sender_id)
            else:
                sender_nickname = "æœªçŸ¥ç”¨æˆ·"
            
            # æ ¼å¼åŒ–å‘é€æ—¶é—´
            create_time = message.create_time
            if create_time:
                # create_time æ˜¯æ¯«ç§’æ—¶é—´æˆ³
                send_time = datetime.fromtimestamp(int(create_time) / 1000).strftime("%Y-%m-%d %H:%M:%S")
            else:
                send_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯å›å¤æ¶ˆæ¯ï¼ˆæœ‰ parent_id æˆ– root_id å°±æ˜¯å›å¤ï¼‰
            is_reply = bool(message.parent_id or message.root_id)
            
            # [è·¯ç”±] è·å–ç›®æ ‡å½’æ¡£æ–‡æ¡£ Token (å·²åœ¨ä¸Šæ–¹è·å–)
            print(f"  > [å½’æ¡£] ç›®æ ‡æ–‡æ¡£: {target_doc_token} (Tag: {matched_tag})")
            
            # æ–°å¢: è·³è¿‡æ— æ ‡ç­¾æ¶ˆæ¯
            if matched_tag == "é»˜è®¤":
                print(f"  > [å½’æ¡£] è·³è¿‡æ— æ ‡ç­¾æ¶ˆæ¯")
            else:
                # è·å–è¢«å›å¤è€…çš„æ˜µç§°ï¼ˆä»…é’ˆå¯¹åµŒå¥—å›å¤ï¼‰
                parent_sender_nickname = None
                if is_reply and message.parent_id and message.root_id and message.parent_id != message.root_id:
                    try:
                        # è·å–çˆ¶æ¶ˆæ¯è¯¦æƒ…
                        parent_msg = collector.get_message_detail(message.parent_id)
                        if parent_msg:
                            # æå–çˆ¶æ¶ˆæ¯å‘é€è€…ID
                            parent_sender = parent_msg.get("sender", {})
                            parent_sender_id_obj = parent_sender.get("sender_id", {})
                            # API è¿”å›çš„ sender_id å¯¹è±¡å¯èƒ½æ˜¯å­—å…¸
                            parent_uid = parent_sender_id_obj.get("user_id") or \
                                       parent_sender_id_obj.get("open_id") or \
                                       parent_sender_id_obj.get("union_id")
                            
                            if parent_uid:
                                parent_sender_nickname = get_cached_nickname(parent_uid)
                    except Exception as e:
                        print(f"  > [å½’æ¡£] è·å–è¢«å›å¤è€…ä¿¡æ¯å¤±è´¥: {e}")

                # è½¬æ¢å†…å®¹ï¼ˆå¸¦å‘é€è€…å’Œæ—¶é—´ï¼Œä»¥åŠæ˜¯å¦æ˜¯å›å¤ï¼‰
                # å¦‚æœåŒ¹é…åˆ°äº†å…·ä½“æ ‡ç­¾ï¼ˆé"é»˜è®¤"ï¼‰ï¼Œåˆ™é€šçŸ¥ convert ç§»é™¤è¯¥æ ‡ç­¾
                tag_to_remove = matched_tag if matched_tag != "é»˜è®¤" else None
                
                blocks = docx_converter.convert(
                    message.content, message.message_id, target_doc_token,
                    sender_name=sender_nickname, send_time=send_time, 
                    is_reply=is_reply, parent_sender_name=parent_sender_nickname,
                    remove_tag=tag_to_remove
                )
                # å†™å…¥æ–‡æ¡£ï¼ˆå›å¤æ¶ˆæ¯éœ€è¦æ’å…¥åœ¨åˆ†å‰²çº¿ä¹‹å‰ï¼‰
                docx_storage.add_blocks(target_doc_token, blocks, insert_before_divider=is_reply)
                print(f"  > [å½’æ¡£] âœ… ç¾¤æ¶ˆæ¯å·²åŒæ­¥ (æ ‡ç­¾: {matched_tag}, Doc: {target_doc_token[-6:]})")
        except Exception as e:
            print(f"  > [å½’æ¡£] âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    content_str = message.content
    char_count = calculator._extract_text_length(content_str)

    print(f"  > æ¶ˆæ¯ID: {message.message_id}")
    print(f"  > çˆ¶ID (parent_id): {message.parent_id or 'None'}")
    print(f"  > æ ¹ID (root_id): {message.root_id or 'None'}")

    # 3. è·å–å‘é€è€…æ˜µç§°
    user_name = get_cached_nickname(sender_id)

    # [Bitableå½’æ¡£] å·²ç¦ç”¨: å½’æ¡£æ¶ˆæ¯åˆ° Bitable (åŒè¡¨æ ¼æ¨¡å¼)
    # try:
    #     file_tokens_for_db, text_content_for_db = _process_message_attachments(message, message.message_id)
    #     create_time_ms = int(message.create_time)
    #     dt_object = datetime.fromtimestamp(create_time_ms / 1000)
    #     month_str = dt_object.strftime("%Y-%m")
    #     archive_fields = _build_archive_fields(...)
    #     if hasattr(archive_storage, "save_message"):
    #         archive_storage.save_message(archive_fields)
    #     _update_topic_summary(...)
    # except Exception as e:
    #     print(f"  > [Bitable] âŒ å½’æ¡£å¤±è´¥: {e}")

    # 4. æ„å»ºæŒ‡æ ‡å¢é‡
    metrics_delta = {
        "message_count": 1,
        "char_count": char_count,
        "reply_received": 0,
        "mention_received": 0,
        "topic_initiated": 1 if not message.root_id else 0,
    }

    # 5. ç´¯ç§¯åˆ°æ‰¹é‡æ›´æ–°å­—å…¸ (æ›¿ä»£åŸæ¥çš„å®æ—¶æ›´æ–°)
    global message_counter
    accumulate_metrics(sender_id, user_name, metrics_delta)

    # 6. ç‰¹æ®Šé€»è¾‘ï¼šå¤„ç†è¢«å›å¤çš„æƒ…å†µ
    parent_id = message.parent_id
    root_id = message.root_id
    already_credited_ids = set()  # è®°å½•æœ¬æ¶ˆæ¯ä¸­å·²ç»è·å¾—"è¢«å›å¤"ç§¯åˆ†çš„äºº

    if parent_id:
        # è¯†åˆ«ç›®æ ‡ç”¨æˆ· ID (target_parent_id)
        target_parent_id = None

        # å¯å‘å¼é€»è¾‘ï¼šåœ¨è¯é¢˜ç¾¤ä¸­ï¼Œparent_id å’Œ root_id é€šå¸¸ç›¸åŒä¸”æŒ‡å‘è¯é¢˜å¤´
        if parent_id == root_id and message.mentions:
            target_parent_id = message.mentions[0].id.open_id
            print(f"  > [æ¢æµ‹] è¯†åˆ«åˆ°è¯é¢˜åµŒå¥—å›å¤: ä½¿ç”¨é¦–ä¸ªè‰¾ç‰¹å¯¹è±¡ {target_parent_id}")
        else:
            # æ™®é€šç¾¤æˆ–ç›´æ¥å›å¤è¯é¢˜ï¼Œä½¿ç”¨çˆ¶æ¶ˆæ¯å‘é€è€…
            target_parent_id = collector.get_message_sender(parent_id)

        if target_parent_id:
            # è·å–è¢«å›å¤è€…æ˜µç§°å¹¶ç´¯ç§¯
            target_user_name = get_cached_nickname(target_parent_id)
            print(f"  > [æ›´æ–°] å¢åŠ è¢«å›å¤æ•°ç»™: {target_user_name}")
            accumulate_metrics(target_parent_id, target_user_name, {"reply_received": 1})
            already_credited_ids.add(target_parent_id)

    # 7. å¤„ç†è¢« @ çš„äºº
    if message.mentions:
        for mention in message.mentions:
            mentioned_id = mention.id.open_id
            if mentioned_id:
                # å¦‚æœè¯¥ç”¨æˆ·åˆšæ‰å·²ç»å› ä¸º"è¢«å›å¤"åŠ è¿‡åˆ†äº†ï¼Œè¿™æ¬¡ @ å°±è·³è¿‡ï¼Œé¿å…é‡å¤è®¡è´¹
                if mentioned_id in already_credited_ids:
                    print(f"  > [è·³è¿‡] {mentioned_id} å·²åœ¨æœ¬æ¬¡ç»Ÿè®¡ä¸­ä½œä¸ºè¢«å›å¤è€…ï¼Œè·³è¿‡è‰¾ç‰¹è®¡è´¹")
                    continue

                mentioned_name = get_cached_nickname(mentioned_id)
                print(f"  > [æ›´æ–°] å¢åŠ è¢«è‰¾ç‰¹æ•°ç»™: {mentioned_name}")
                accumulate_metrics(mentioned_id, mentioned_name, {"mention_received": 1})

    # 8. æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡æ›´æ–°
    message_counter += 1
    if message_counter >= BATCH_UPDATE_THRESHOLD:
        flush_pending_updates()
        message_counter = 0

    print("âœ… æ¶ˆæ¯å¤„ç†å®Œæˆ")


def _process_message_attachments(message, message_id: str) -> list:
    """
    å¤„ç†æ¶ˆæ¯é™„ä»¶ï¼ˆå›¾ç‰‡å’Œæ–‡ä»¶ï¼‰

    Args:
        message: æ¶ˆæ¯å¯¹è±¡
        message_id: æ¶ˆæ¯ID

    Returns:
        file_tokensåˆ—è¡¨ï¼ŒåŒ…å«ä¸Šä¼ åçš„é™„ä»¶ä¿¡æ¯
    """
    file_tokens = []

    # æå–çº¯æ–‡æœ¬å’ŒåµŒå…¥çš„å›¾ç‰‡ keys
    text_content, embedded_image_keys = MetricsCalculator.extract_text_from_content(message.content)

    # å¤„ç†å¯Œæ–‡æœ¬ä¸­åµŒå…¥çš„å›¾ç‰‡
    if embedded_image_keys:
        for img_key in embedded_image_keys:
            print(f"  > [é™„ä»¶] æ­£åœ¨å¤„ç†å¯Œæ–‡æœ¬åµŒå…¥å›¾ç‰‡: {img_key}")
            file_bin = archive_storage.download_message_resource(message_id, img_key, "image")
            if file_bin:
                attachment_obj = archive_storage.upload_file_to_drive(file_bin, f"{img_key}.png")
                if attachment_obj:
                    file_tokens.append(attachment_obj)

    # è§£æcontentè·å–æ–‡ä»¶ä¿¡æ¯
    try:
        content_obj = (
            json.loads(message.content) if isinstance(message.content, str) else message.content
        )
    except (json.JSONDecodeError, ValueError):
        content_obj = {}

    # å¤„ç†ç‹¬ç«‹çš„å›¾ç‰‡æ¶ˆæ¯
    if message.message_type == "image":
        file_key = content_obj.get("image_key")
        if file_key:
            print(f"  > [é™„ä»¶] æ­£åœ¨å¤„ç†å›¾ç‰‡æ¶ˆæ¯: {file_key}")
            file_bin = archive_storage.download_message_resource(message_id, file_key, "image")
            if file_bin:
                attachment_obj = archive_storage.upload_file_to_drive(file_bin, f"{file_key}.png")
                if attachment_obj:
                    file_tokens.append(attachment_obj)

    # å¤„ç†æ–‡ä»¶æ¶ˆæ¯
    elif message.message_type == "file":
        file_key = content_obj.get("file_key")
        file_name = content_obj.get("file_name", "file")
        if file_key:
            print(f"  > [é™„ä»¶] æ­£åœ¨å¤„ç†æ–‡ä»¶æ¶ˆæ¯: {file_name}")
            file_bin = archive_storage.download_message_resource(message_id, file_key, "file")
            if file_bin:
                attachment_obj = archive_storage.upload_file_to_drive(file_bin, file_name)
                if attachment_obj:
                    file_tokens.append(attachment_obj)

    return file_tokens, text_content


def _build_archive_fields(
    message,
    sender_id: str,
    user_name: str,
    text_content: str,
    file_tokens: list,
    month_str: str,
    timestamp_ms: int,
) -> dict:
    """
    æ„å»ºæ¶ˆæ¯å½’æ¡£å­—æ®µ

    Args:
        message: æ¶ˆæ¯å¯¹è±¡
        sender_id: å‘é€è€…ID
        user_name: å‘é€è€…å§“å
        text_content: æ¶ˆæ¯æ–‡æœ¬å†…å®¹
        file_tokens: é™„ä»¶åˆ—è¡¨
        month_str: ç»Ÿè®¡æœˆä»½
        timestamp_ms: æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰

    Returns:
        å½’æ¡£å­—æ®µå­—å…¸
    """
    # æ„å»ºæ¶ˆæ¯é“¾æ¥
    message_link = {
        "link": f"https://applink.feishu.cn/client/chat/open?openChatId={CHAT_ID}&messageId={message.message_id}",
        "text": "æŸ¥çœ‹æ¶ˆæ¯",
    }

    archive_fields = {
        "æ¶ˆæ¯ID": message.message_id,
        "è¯é¢˜ID": message.root_id or message.message_id,
        "çˆ¶æ¶ˆæ¯ID": message.parent_id or "",
        "å‘é€è€…": [{"id": sender_id}],
        "å‘é€è€…å§“å": user_name,
        "æ¶ˆæ¯å†…å®¹": text_content,
        "æ¶ˆæ¯ç±»å‹": message.message_type,
        "å‘é€æ—¶é—´": timestamp_ms,
        "ç»Ÿè®¡æœˆä»½": month_str,
        "æ¶ˆæ¯é“¾æ¥": message_link,
    }

    # æ·»åŠ é™„ä»¶ä¿¡æ¯
    if file_tokens:
        archive_fields["é™„ä»¶ä¿¡æ¯"] = file_tokens

    # æ·»åŠ @çš„äºº
    if message.mentions:
        mention_names = [m.name for m in message.mentions]
        archive_fields["@çš„äºº"] = ", ".join(mention_names)

    return archive_fields


def _get_topic_status(last_reply_time_ms: int) -> str:
    """
    æ ¹æ®æœ€åå›å¤æ—¶é—´åˆ¤æ–­è¯é¢˜çŠ¶æ€

    Args:
        last_reply_time_ms: æœ€åå›å¤æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰

    Returns:
        è¯é¢˜çŠ¶æ€ï¼šæ´»è·ƒ/æ²‰é»˜/å†·å´
    """
    if not last_reply_time_ms:
        return "æ´»è·ƒ"

    now = datetime.now()
    last_reply_time = datetime.fromtimestamp(last_reply_time_ms / 1000)
    days_since_last_reply = (now - last_reply_time).days

    if days_since_last_reply <= TOPIC_ACTIVE_DAYS:
        return "æ´»è·ƒ"
    elif days_since_last_reply <= TOPIC_SILENT_DAYS:
        return "æ²‰é»˜"
    else:
        return "å†·å´"


def _update_topic_summary(
    message,
    sender_id: str,
    user_name: str,
    text_content: str,
    root_id: str,
    month_str: str,
    timestamp_ms: int,
):
    """
    æ›´æ–°æˆ–åˆ›å»ºè¯é¢˜æ±‡æ€»

    Args:
        message: æ¶ˆæ¯å¯¹è±¡
        sender_id: å‘é€è€…ID
        user_name: å‘é€è€…å§“å
        text_content: æ¶ˆæ¯æ–‡æœ¬å†…å®¹
        root_id: è¯é¢˜æ ¹æ¶ˆæ¯ID
        month_str: ç»Ÿè®¡æœˆä»½
        timestamp_ms: æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    """
    topic_record = archive_storage.get_topic_by_id(root_id)

    # æ„å»ºè¯é¢˜é“¾æ¥
    topic_link = {
        "link": f"https://applink.feishu.cn/client/chat/open?openChatId={CHAT_ID}&messageId={root_id}",
        "text": "æŸ¥çœ‹è¯é¢˜",
    }

    if not topic_record:
        # åˆ›å»ºæ–°è¯é¢˜
        summary_fields = {
            "è¯é¢˜ID": root_id,
            "è¯é¢˜æ ‡é¢˜": text_content,
            "å‘èµ·äºº": [{"id": sender_id}],
            "å‘èµ·äººå§“å": user_name,
            "åˆ›å»ºæ—¶é—´": timestamp_ms,
            "æœ€åå›å¤æ—¶é—´": timestamp_ms,
            "å›å¤æ•°": 0 if not message.root_id else 1,
            "å‚ä¸äººæ•°": 1,
            "å‚ä¸è€…": user_name,
            "è¯é¢˜çŠ¶æ€": "æ´»è·ƒ",
            "ç»Ÿè®¡æœˆä»½": month_str,
            "è¯é¢˜é“¾æ¥": topic_link,
        }
        archive_storage.update_or_create_topic(root_id, summary_fields, is_new=True)
    else:
        # æ›´æ–°å·²æœ‰è¯é¢˜
        old_fields = topic_record["fields"]

        # æ›´æ–°å‚ä¸è€…åˆ—è¡¨
        participants = set()
        participants_raw = old_fields.get("å‚ä¸è€…", "")

        if isinstance(participants_raw, list):
            for item in participants_raw:
                if isinstance(item, dict):
                    name = item.get("text", "")
                    if name:
                        participants.add(name)
                elif isinstance(item, str) and item:
                    participants.add(item)
        elif isinstance(participants_raw, str) and participants_raw:
            for name in participants_raw.split(", "):
                if name.strip():
                    participants.add(name.strip())

        participants.add(user_name)

        # è®¡ç®—è¯é¢˜çŠ¶æ€
        topic_status = _get_topic_status(timestamp_ms)

        summary_fields = {
            "æœ€åå›å¤æ—¶é—´": timestamp_ms,
            "å›å¤æ•°": int(old_fields.get("å›å¤æ•°", 0)) + 1,
            "å‚ä¸äººæ•°": len(participants),
            "å‚ä¸è€…": ", ".join(participants),
            "è¯é¢˜çŠ¶æ€": topic_status,
        }
        archive_storage.update_or_create_topic(root_id, summary_fields, is_new=False)




def do_p2_im_message_reaction_created_v1(data: lark.im.v1.P2ImMessageReactionCreatedV1) -> None:
    """å¤„ç†è¡¨æƒ…å›å¤äº‹ä»¶ï¼ˆç‚¹èµï¼‰"""
    from health_monitor import update_event_processed
    
    # 0. äº‹ä»¶å»é‡
    event_id = data.header.event_id
    if event_id in processed_events:
        return
    processed_events.set(event_id, True)  # LRUä¼šè‡ªåŠ¨ç®¡ç†å®¹é‡ï¼Œæ— éœ€æ‰‹åŠ¨æ¸…ç†

    event = data.event
    
    # æ›´æ–°å¥åº·ç›‘æ§çŠ¶æ€
    update_event_processed("reaction")

    # è·å–æ“ä½œè€…IDï¼ˆç‚¹èµçš„äººï¼‰
    operator_id = event.user_id.open_id if event.user_id else None
    if not operator_id:
        return

    # è·å–æ¶ˆæ¯ID
    message_id = event.message_id
    if not message_id:
        return

    # [V3-LOG] è¡¨æƒ…å›å¤äº‹ä»¶è¿½è¸ª
    now_str = datetime.now().strftime("%H:%M:%S")
    print(f"\n[V3-LOG] [{now_str}] æ”¶åˆ°è¡¨æƒ…å›å¤äº‹ä»¶===================")
    print(f"  > æ¶ˆæ¯ID: {message_id}")
    print(f"  > æ“ä½œè€…ID: {operator_id}")

    try:
        # 1. è·å–æ¶ˆæ¯çš„å‘é€è€…ï¼ˆè¢«ç‚¹èµçš„äººï¼‰
        message_sender_id = collector.get_message_sender(message_id)
        if not message_sender_id:
            print(f"  > [è·³è¿‡] æ— æ³•è·å–æ¶ˆæ¯å‘é€è€…")
            return

        # 2. è·å–æ˜µç§°
        operator_name = get_cached_nickname(operator_id)
        receiver_name = get_cached_nickname(message_sender_id)

        print(f"  > ç‚¹èµè€…: {operator_name}")
        print(f"  > è¢«ç‚¹èµè€…: {receiver_name}")

        # 3. æ›´æ–°ç‚¹èµè€…çš„"ç‚¹èµæ•°"
        storage.update_or_create_record(
            user_id=operator_id, user_name=operator_name, metrics_delta={"reaction_given": 1}
        )

        # 4. æ›´æ–°è¢«ç‚¹èµè€…çš„"è¢«ç‚¹èµæ•°"
        if message_sender_id != operator_id:  # é¿å…è‡ªå·±ç»™è‡ªå·±ç‚¹èµçš„æƒ…å†µ
            storage.update_or_create_record(
                user_id=message_sender_id,
                user_name=receiver_name,
                metrics_delta={"reaction_received": 1},
            )
        else:
            print(f"  > [è·³è¿‡] ç”¨æˆ·ç»™è‡ªå·±ç‚¹èµ")

        print("âœ… è¡¨æƒ…å›å¤ç»Ÿè®¡æˆåŠŸ")

    except Exception as e:
        print(f"âŒ è¡¨æƒ…å›å¤ç»Ÿè®¡å¤±è´¥: {e}")


# åˆå§‹åŒ–äº‹ä»¶å¤„ç†å™¨
event_handler = (
    lark.EventDispatcherHandler.builder("", "")
    .register_p2_im_message_receive_v1(do_p2_im_message_receive_v1)
    .register_p2_im_message_reaction_created_v1(do_p2_im_message_reaction_created_v1)
    .build()
)


def main():
    """
    ä¸»å‡½æ•° - å¯åŠ¨é£ä¹¦æ´»è·ƒåº¦ç›‘æ§æœåŠ¡
    
    åŒ…å«ä»¥ä¸‹å¢å¼ºåŠŸèƒ½ï¼š
    1. ç¯å¢ƒå˜é‡éªŒè¯
    2. å¥åº·æ£€æŸ¥HTTPæœåŠ¡
    3. è‡ªåŠ¨é‡è¿æœºåˆ¶
    4. Pinç›‘æ§ï¼ˆå¯é€‰ï¼‰
    """
    import time
    from env_validator import validate_environment
    from health_monitor import start_health_monitor, update_websocket_connected, health_monitor
    
    # ========== 1. ç¯å¢ƒå˜é‡éªŒè¯ ==========
    try:
        validate_environment()
    except ValueError as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥ï¼š{e}")
        print("\nè¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®ï¼Œå‚è€ƒ .env.example æ¨¡æ¿")
        return
    
    # ========== 2. å¯åŠ¨å¥åº·æ£€æŸ¥æœåŠ¡ ==========
    health_port = int(os.getenv("HEALTH_CHECK_PORT", 8080))
    try:
        start_health_monitor(port=health_port)
    except Exception as e:
        print(f"âš ï¸ å¥åº·æ£€æŸ¥æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        print("   å°†ç»§ç»­è¿è¡Œä¸»æœåŠ¡ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰")
    
    # ========== 3. è‡ªåŠ¨é‡è¿å¾ªç¯ ==========
    retry_count = 0
    max_retries = int(os.getenv("MAX_RETRIES", 10))  # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay = int(os.getenv("RETRY_DELAY", 30))  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    pin_monitor = None
    
    while retry_count < max_retries:
        try:
            # åˆå§‹åŒ–Pinç›‘æ§ï¼ˆæ¯æ¬¡é‡è¿éƒ½é‡æ–°åˆå§‹åŒ–ï¼‰
            pin_table_id = os.getenv("PIN_TABLE_ID")
            pin_interval = int(os.getenv("PIN_MONITOR_INTERVAL", 30))
            
            if pin_table_id and not pin_monitor:
                print(f"ğŸ” Pinç›‘æ§å·²å¯ç”¨ (è½®è¯¢é—´éš”: {pin_interval}ç§’)")
                # æ³¨å…¥ç²¾åæ–‡æ¡£å½’æ¡£é…ç½®
                essence_doc_token = os.getenv("ESSENCE_DOC_TOKEN")
                pin_monitor = PinMonitor(
                    auth, storage, CHAT_ID, interval=pin_interval,
                    docx_storage=docx_storage, essence_doc_token=essence_doc_token
                )
                pin_monitor.start()
                health_monitor.set_pin_monitor_status(True)
            
            # å¯åŠ¨ Pin å‘¨æŠ¥è°ƒåº¦å™¨ (åå°çº¿ç¨‹,é›†æˆåˆ°ä¸»è¿›ç¨‹)
            print("\nğŸ“… å¯åŠ¨ Pin å‘¨æŠ¥è°ƒåº¦å™¨...")
            try:
                start_pin_scheduler()
            except Exception as e:
                print(f"âš ï¸  Pin å‘¨æŠ¥è°ƒåº¦å™¨å¯åŠ¨å¤±è´¥: {e}")
                print("âš ï¸  å°†ç»§ç»­è¿è¡Œ,ä½† Pin å‘¨æŠ¥åŠŸèƒ½ä¸å¯ç”¨")
            
            # åˆå§‹åŒ–é•¿è¿æ¥å®¢æˆ·ç«¯
            cli = lark.ws.Client(
                APP_ID, 
                APP_SECRET, 
                event_handler=event_handler, 
                log_level=lark.LogLevel.INFO  # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨INFOçº§åˆ«
            )
            
            print("\n" + "=" * 60)
            if retry_count == 0:
                print("ğŸš€ é£ä¹¦å®æ—¶ç›‘å¬æœåŠ¡å¯åŠ¨")
            else:
                print(f"ğŸ”„ æ­£åœ¨é‡æ–°è¿æ¥ (å°è¯• {retry_count + 1}/{max_retries})")
            print(f"ğŸ“… ç³»ç»Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"âœ¨ ç‰¹æ€§: ç¯å¢ƒéªŒè¯ | å¥åº·æ£€æŸ¥:{health_port} | è‡ªåŠ¨é‡è¿ | LRUç¼“å­˜ | APIé™æµ")
            print("=" * 60 + "\n")
            
            # æ›´æ–°å¥åº·çŠ¶æ€
            update_websocket_connected(True)
            
            # å¯åŠ¨WebSocketå®¢æˆ·ç«¯ï¼ˆé˜»å¡è°ƒç”¨ï¼‰
            cli.start()
            
            # å¦‚æœæ­£å¸¸é€€å‡ºï¼ˆä¸æ˜¯å¼‚å¸¸ï¼‰ï¼Œé‡ç½®é‡è¯•è®¡æ•°
            retry_count = 0
            print("\nâœ… WebSocketå®¢æˆ·ç«¯æ­£å¸¸é€€å‡º")
            
        except KeyboardInterrupt:
            # ç”¨æˆ·ä¸»åŠ¨ä¸­æ–­
            print("\n\nâš ï¸ æ”¶åˆ°é€€å‡ºä¿¡å· (Ctrl+C)")
            print("æ­£åœ¨å®‰å…¨å…³é—­æœåŠ¡...")
            update_websocket_connected(False)
            break
            
        except Exception as e:
            # è¿æ¥å¼‚å¸¸ï¼Œå‡†å¤‡é‡è¯•
            retry_count += 1
            update_websocket_connected(False)
            
            print("\n" + "=" * 60)
            print(f"âŒ è¿æ¥å¼‚å¸¸ (å°è¯• {retry_count}/{max_retries})")
            print(f"   é”™è¯¯ä¿¡æ¯: {e}")
            print("=" * 60)
            
            if retry_count >= max_retries:
                print(f"\nâŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œç¨‹åºé€€å‡º")
                print("   å»ºè®®æ£€æŸ¥ï¼š")
                print("   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
                print("   2. APP_IDå’ŒAPP_SECRETæ˜¯å¦æ­£ç¡®")
                print("   3. é£ä¹¦åº”ç”¨æ˜¯å¦å·²å¼€é€šé•¿è¿æ¥æƒé™")
                break
            
            print(f"â³ {retry_delay} ç§’åè‡ªåŠ¨é‡è¿...\n")
            time.sleep(retry_delay)
            
            # æŒ‡æ•°é€€é¿ï¼šæ¯æ¬¡é‡è¯•å»¶è¿ŸåŠ å€ï¼Œæœ€å¤š60ç§’
            retry_delay = min(retry_delay * 2, 60)
        
        finally:
            # æ— è®ºå¦‚ä½•éƒ½ç¡®ä¿Pinç›‘æ§è¢«åœæ­¢
            if pin_monitor:
                try:
                    # åªåœ¨æœ€ç»ˆé€€å‡ºæ—¶åœæ­¢Pinç›‘æ§
                    if retry_count >= max_retries or KeyboardInterrupt:
                        print("æ­£åœ¨åœæ­¢Pinç›‘æ§...")
                        pin_monitor.stop()
                        pin_monitor = None
                        health_monitor.set_pin_monitor_status(False)
                except Exception as e:
                    print(f"âš ï¸ åœæ­¢Pinç›‘æ§æ—¶å‡ºé”™: {e}")
            
            # åœæ­¢ Pin å‘¨æŠ¥è°ƒåº¦å™¨
            try:
                print("ğŸš¦ æ­£åœ¨åœæ­¢ Pin å‘¨æŠ¥è°ƒåº¦å™¨...")
                stop_pin_scheduler()
            except Exception as e:
                print(f"âš ï¸  åœæ­¢ Pin å‘¨æŠ¥è°ƒåº¦å™¨æ—¶å‡ºé”™: {e}")
    
    # ========== 4. æ¸…ç†å’Œé€€å‡º ==========
    print("\n" + "=" * 60)
    print("âœ… ç¨‹åºå·²å®‰å…¨é€€å‡º")
    print(f"ğŸ“Š è¿è¡Œç»Ÿè®¡: å¤„ç†äº† {health_monitor.status['total_events_processed']} ä¸ªäº‹ä»¶")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()
